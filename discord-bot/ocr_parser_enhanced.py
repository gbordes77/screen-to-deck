#!/usr/bin/env python3
"""
üîß CORRECTIF GLOBAL pour ocr_parser.py
Cette version int√®gre :
1. Un pipeline de pr√©traitement d'image robuste pour am√©liorer radicalement l'OCR.
2. L'utilisation de la recherche floue (fuzzy) sur Scryfall pour plus de tol√©rance.
3. La correction du bug de transmission des donn√©es au DeckProcessor.
"""

import cv2
import pytesseract
import numpy as np
import re
import logging
import os
import asyncio
from typing import List, Tuple, Dict, Any, Optional
from dataclasses import dataclass, field

from deck_processor import DeckProcessor, ProcessedCard, ValidationResult
from scryfall_service import ScryfallService

# Configuration du logger
logger = logging.getLogger("ocr_parser_enhanced")
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

# --- Dataclasses (mis √† jour) ---
@dataclass
class ParsedCard:
    name: str
    quantity: int
    original_text: str
    is_sideboard: bool
    confidence: float = 0.0
    is_validated: bool = False
    correction_applied: bool = False
    scryfall_data: Optional[Dict[str, Any]] = None
    suggestions: Optional[List[str]] = None

@dataclass
class ParseResult:
    cards: List[ParsedCard] = field(default_factory=list)
    processed_cards: List[ProcessedCard] = field(default_factory=list)
    validation: Optional[ValidationResult] = None
    export_text: Optional[str] = None
    errors: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)
    confidence_score: float = 0.0
    processing_notes: List[str] = field(default_factory=list)
    total_cards: int = 0
    main_count: int = 0
    side_count: int = 0
    format_analysis: Optional[Any] = None

# --- Module OCR Am√©lior√© ---
class AdvancedMTGArenaOCR:
    """
    Module OCR avec un pipeline de pr√©traitement d'image avanc√©
    pour une reconnaissance de caract√®res de haute fid√©lit√©.
    """
    def __init__(self, lang='eng'):
        self.lang = lang
        # Configuration Tesseract optimis√©e pour les noms de cartes MTG
        self.tesseract_config = (
            '--oem 3 --psm 6 '
            '-c tessedit_char_whitelist="'
            'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'
            '0123456789 ,.\'-/:&"'
        )
        logger.info(f"AdvancedOCR initialis√© avec la config: {self.tesseract_config}")

    def _preprocess_image(self, image: np.ndarray) -> np.ndarray:
        """
        Applique une cha√Æne de pr√©traitement robuste pour maximiser la qualit√© de l'OCR.
        """
        logger.info("üîß D√©but du pr√©traitement d'image avanc√©")
        
        # 1. Mise √† l'√©chelle pour une hauteur de caract√®res optimale
        h, w = image.shape[:2]
        target_height = 1600  # Augment√© pour plus de pr√©cision
        scale_factor = target_height / h
        scaled = cv2.resize(image, (int(w * scale_factor), int(h * scale_factor)), 
                           interpolation=cv2.INTER_LANCZOS4)
        logger.info(f"  üìè Image redimensionn√©e: {w}x{h} ‚Üí {scaled.shape[1]}x{scaled.shape[0]} (facteur: {scale_factor:.2f})")
        
        # 2. Conversion en niveaux de gris
        gray = cv2.cvtColor(scaled, cv2.COLOR_BGR2GRAY)
        
        # 3. D√©bruitage avanc√© multi-√©tapes
        # √âtape 3a: Filtre m√©dian pour √©liminer le bruit impulsionnel
        median_filtered = cv2.medianBlur(gray, 3)
        
        # √âtape 3b: Filtre gaussien pour lisser
        denoised = cv2.GaussianBlur(median_filtered, (3, 3), 0)
        
        # √âtape 3c: Filtre bilat√©ral pour pr√©server les contours
        bilateral = cv2.bilateralFilter(denoised, 9, 75, 75)
        
        # 4. Am√©lioration du contraste avec CLAHE
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
        enhanced = clahe.apply(bilateral)
        
        # 5. Essayer plusieurs m√©thodes de binarisation et garder la meilleure
        # M√©thode 1: Binarisation adaptative
        binary1 = cv2.adaptiveThreshold(
            enhanced, 255,
            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY,
            15,  # Taille du bloc augment√©e
            4    # Constante C
        )
        
        # M√©thode 2: Binarisation d'Otsu
        _, binary2 = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        # M√©thode 3: Binarisation adaptative avec moyenne
        binary3 = cv2.adaptiveThreshold(
            enhanced, 255,
            cv2.ADAPTIVE_THRESH_MEAN_C,
            cv2.THRESH_BINARY,
            15, 8
        )
        
        # Sauvegarder les diff√©rentes versions pour debug
        cv2.imwrite("debug_adaptive.png", binary1)
        cv2.imwrite("debug_otsu.png", binary2)
        cv2.imwrite("debug_mean.png", binary3)
        
        # Utiliser la binarisation adaptative par d√©faut
        binary = binary1
        
        # 6. Nettoyage morphologique pour √©liminer le bruit
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
        cleaned = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
        
        # 7. Dilatation l√©g√®re pour am√©liorer la connectivit√© des caract√®res
        kernel_dilate = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 1))
        final = cv2.dilate(cleaned, kernel_dilate, iterations=1)
        
        logger.info("  ‚úÖ Pr√©traitement d'image termin√©")
        return final

    def extract_text_from_image(self, image_path: str) -> str:
        """
        Traite une image compl√®te et en extrait le texte brut.
        """
        logger.info(f"üîç D√©but de l'extraction de texte depuis : {image_path}")
        try:
            image = cv2.imread(image_path)
            if image is None:
                raise FileNotFoundError(f"Image introuvable ou illisible √† : {image_path}")

            preprocessed_image = self._preprocess_image(image)
            
            # Sauvegarder l'image pr√©trait√©e pour le d√©bogage
            debug_path = "preprocessed_debug.png"
            cv2.imwrite(debug_path, preprocessed_image)
            logger.info(f"  üíæ Image pr√©trait√©e sauvegard√©e : {debug_path}")

            text = pytesseract.image_to_string(preprocessed_image, config=self.tesseract_config)
            logger.info("  ‚úÖ Extraction de texte par Tesseract termin√©e")
            logger.info(f"  üìù Texte extrait ({len(text)} caract√®res)")
            
            return text

        except Exception as e:
            logger.error(f"‚ùå Erreur lors du traitement OCR de {image_path}: {e}", exc_info=True)
            return ""

# --- Parser Principal Corrig√© ---
class MTGOCRParser:
    """
    Parser principal qui utilise l'OCR avanc√©, la recherche floue et
    corrige le flux de donn√©es vers le DeckProcessor.
    """
    def __init__(self, scryfall_service: ScryfallService):
        self.scryfall_service = scryfall_service
        self.arena_ocr = AdvancedMTGArenaOCR()
        self.deck_processor = DeckProcessor(strict_mode=False)
        self.logger = logger

    def _filter_ocr_noise(self, text: str) -> str:
        """
        üîß FILTRAGE INTELLIGENT DU BRUIT OCR
        Nettoie le texte OCR en supprimant les lignes qui ne peuvent pas √™tre des noms de cartes
        """
        lines = text.split('\n')
        filtered_lines = []
        
        for line in lines:
            line = line.strip()
            
            # Ignorer les lignes vides ou trop courtes
            if not line or len(line) < 3:
                continue
            
            # Ignorer les lignes avec trop de caract√®res sp√©ciaux
            special_chars = sum(1 for c in line if not c.isalnum() and c not in ' \'-')
            if special_chars > len(line) * 0.4:  # Plus de 40% de caract√®res sp√©ciaux
                logger.debug(f"  üóëÔ∏è Ligne rejet√©e (trop de caract√®res sp√©ciaux): '{line[:30]}...'")
                continue
            
            # Ignorer les lignes avec des s√©quences r√©p√©titives suspectes
            if re.search(r'(.{3,})\1{2,}', line):  # R√©p√©tition de 3+ caract√®res
                logger.debug(f"  üóëÔ∏è Ligne rejet√©e (r√©p√©tition suspecte): '{line[:30]}...'")
                continue
            
            # Ignorer les lignes qui ressemblent √† du texte de r√®gles
            rules_keywords = ['when', 'if', 'target', 'draw', 'damage', 'graveyard', 'battlefield', 'enters', 'cast']
            if any(keyword in line.lower() for keyword in rules_keywords):
                logger.debug(f"  üóëÔ∏è Ligne rejet√©e (texte de r√®gles): '{line[:30]}...'")
                continue
            
            # Ignorer les lignes avec trop de mots courts (probablement du bruit)
            words = line.split()
            short_words = sum(1 for word in words if len(word) <= 2)
            if len(words) > 3 and short_words > len(words) * 0.6:
                logger.debug(f"  üóëÔ∏è Ligne rejet√©e (trop de mots courts): '{line[:30]}...'")
                continue
            
            filtered_lines.append(line)
        
        filtered_text = '\n'.join(filtered_lines)
        logger.info(f"  üßπ Filtrage OCR: {len(lines)} ‚Üí {len(filtered_lines)} lignes conserv√©es")
        return filtered_text

    def _parse_raw_text(self, text: str) -> Tuple[List[Tuple[str, int]], List[Tuple[str, int]]]:
        """
        Analyse le texte brut de l'OCR pour s√©parer le deck principal du sideboard.
        Retourne deux listes de tuples (nom_brut, quantit√©).
        """
        logger.info("üìã Parsing du texte brut OCR")
        
        # NOUVEAU: Filtrage intelligent du bruit OCR
        filtered_text = self._filter_ocr_noise(text)
        
        main_cards = []
        side_cards = []
        is_sideboard = False
        
        # Patterns de reconnaissance am√©lior√©s
        patterns = [
            (r'^\s*(\d+)\s+(.+)$', lambda m: (int(m.group(1)), m.group(2).strip())),
            (r'^\s*(\d+)x\s+(.+)$', lambda m: (int(m.group(1)), m.group(2).strip())),
            (r'^\s*(.+?)\s+x?(\d+)\s*$', lambda m: (int(m.group(2)), m.group(1).strip())),
            (r'^\s*(.+)$', lambda m: (1, m.group(1).strip()))  # D√©faut: quantit√© = 1
        ]

        for line in filtered_text.split('\n'):
            line = line.strip()
            if not line or len(line) < 3:
                continue

            # D√©tection du passage au sideboard
            if line.lower() in ['sideboard', 'side', 'reserve', 'sb']:
                is_sideboard = True
                logger.info("  üîÑ Passage au sideboard d√©tect√©")
                continue
            
            # Ignorer l'en-t√™te "Deck"
            if line.lower() in ['deck', 'main', 'maindeck']:
                continue

            # Essayer les patterns de reconnaissance
            quantity = 1
            name = line
            
            for pattern, extractor in patterns:
                match = re.match(pattern, line)
                if match:
                    try:
                        quantity, name = extractor(match)
                        break
                    except (ValueError, IndexError):
                        continue
            
            # Nettoyage am√©lior√© du nom de carte
            name = re.sub(r'[^\w\s\'-/]', '', name).strip()  # Garder les '/' pour les cartes double-face
            name = re.sub(r'\s+', ' ', name)  # Normaliser les espaces
            
            if not name or len(name) < 3:  # Augment√© √† 3 caract√®res minimum
                continue

            if is_sideboard:
                side_cards.append((name, quantity))
                logger.debug(f"  [SIDE] {quantity}x {name}")
            else:
                main_cards.append((name, quantity))
                logger.debug(f"  [MAIN] {quantity}x {name}")

        logger.info(f"  ‚úÖ Parsing termin√©. Main: {len(main_cards)} entr√©es, Side: {len(side_cards)} entr√©es")
        return main_cards, side_cards

    async def _validate_and_normalize_cards(self, card_tuples: List[Tuple[str, int]], is_sideboard: bool) -> List[ParsedCard]:
        """
        Valide une liste de cartes brutes avec la recherche floue Scryfall.
        """
        zone_name = "sideboard" if is_sideboard else "main"
        logger.info(f"üîç Validation {zone_name} avec recherche floue Scryfall")
        
        validated_list = []
        for name, quantity in card_tuples:
            logger.info(f"  üîé Validation de '{name}'...")
            
            try:
                # Utilisation de la recherche FUZZY existante
                match_data = await self.scryfall_service.search_card_fuzzy(name)

                if match_data:
                    canonical_name = match_data['name']
                    logger.info(f"    ‚úÖ Succ√®s: '{name}' ‚Üí '{canonical_name}'")
                    validated_list.append(ParsedCard(
                        name=canonical_name,
                        quantity=quantity,
                        original_text=f"{quantity} {name}",
                        is_sideboard=is_sideboard,
                        is_validated=True,
                        correction_applied=(name.lower() != canonical_name.lower()),
                        scryfall_data=match_data,
                        confidence=0.9
                    ))
                else:
                    logger.warning(f"    ‚ö†Ô∏è √âchec: Impossible de valider '{name}'")
                    # Garder la carte non valid√©e pour l'afficher √† l'utilisateur
                    validated_list.append(ParsedCard(
                        name=name,
                        quantity=quantity,
                        original_text=f"{quantity} {name}",
                        is_sideboard=is_sideboard,
                        is_validated=False,
                        confidence=0.3
                    ))
            except Exception as e:
                logger.error(f"    ‚ùå Erreur lors de la validation de '{name}': {e}")
                validated_list.append(ParsedCard(
                    name=name,
                    quantity=quantity,
                    original_text=f"{quantity} {name}",
                    is_sideboard=is_sideboard,
                    is_validated=False,
                    confidence=0.1
                ))
                
        logger.info(f"  ‚úÖ Validation {zone_name} termin√©e: {len(validated_list)} cartes")
        return validated_list

    async def parse_deck_image(self, image_path: str, language: str = 'en', format_hint: str = 'standard') -> ParseResult:
        """
        Pipeline complet : OCR > Parsing > Validation Floue > Regroupement > Export.
        """
        logger.info(f"üöÄ D√âBUT DU PIPELINE COMPLET AM√âLIOR√â POUR {image_path}")

        try:
            # 1. OCR avanc√© pour obtenir le texte brut
            logger.info("üì∑ Phase 1: OCR avanc√©")
            raw_text = self.arena_ocr.extract_text_from_image(image_path)
            if not raw_text or len(raw_text.strip()) < 10:
                return ParseResult(
                    errors=["√âchec critique de l'OCR. L'image est peut-√™tre vide ou illisible."],
                    processing_notes=["OCR n'a produit aucun texte exploitable"]
                )

            # 2. Analyse du texte brut pour s√©parer deck/sideboard
            logger.info("üìã Phase 2: Parsing du texte")
            raw_main, raw_side = self._parse_raw_text(raw_text)

            if not raw_main and not raw_side:
                return ParseResult(
                    errors=["Aucune carte d√©tect√©e dans le texte OCR"],
                    processing_notes=[f"Texte OCR brut: {raw_text[:200]}..."]
                )

            # 3. Validation et normalisation avec Scryfall (recherche floue)
            logger.info("üîç Phase 3: Validation Scryfall avec recherche floue")
            validated_main = await self._validate_and_normalize_cards(raw_main, is_sideboard=False)
            validated_side = await self._validate_and_normalize_cards(raw_side, is_sideboard=True)

            all_cards = validated_main + validated_side
            validated_cards = [c for c in all_cards if c.is_validated]

            if not validated_cards:
                return ParseResult(
                    cards=all_cards,
                    errors=["Aucune carte n'a pu √™tre valid√©e avec Scryfall"],
                    warnings=["Toutes les cartes d√©tect√©es ont √©chou√© √† la validation"],
                    processing_notes=[f"Cartes d√©tect√©es mais non valid√©es: {[c.name for c in all_cards]}"]
                )

            # 4. Regroupement avec DeckProcessor (FLUX DE DONN√âES CORRIG√â)
            logger.info("üéØ Phase 4: Regroupement intelligent")
            main_tuples = [(c.name, c.quantity) for c in validated_cards if not c.is_sideboard]
            side_tuples = [(c.name, c.quantity) for c in validated_cards if c.is_sideboard]

            logger.info(f"  üìä Donn√©es pour DeckProcessor: {len(main_tuples)} main, {len(side_tuples)} side")
            
            processed_cards, validation = self.deck_processor.process_deck(main_tuples, side_tuples)
            
            # 5. G√©n√©ration du texte d'export final
            logger.info("üì§ Phase 5: G√©n√©ration de l'export")
            export_text = self.deck_processor.export_to_format(processed_cards, 'mtga')
            
            # 6. Calcul des statistiques
            confidence_score = sum(c.confidence for c in validated_cards) / len(validated_cards) if validated_cards else 0.0
            
            processing_notes = [
                f"OCR avanc√© appliqu√© avec succ√®s",
                f"Recherche floue Scryfall utilis√©e",
                f"Cartes valid√©es: {len(validated_cards)}/{len(all_cards)}",
                f"Regroupement: {len(all_cards)} ‚Üí {len(processed_cards)} cartes uniques"
            ]

            logger.info("üéâ PIPELINE TERMIN√â AVEC SUCC√àS")

            return ParseResult(
                cards=all_cards,
                processed_cards=processed_cards,
                validation=validation,
                export_text=export_text,
                warnings=validation.warnings if validation else [],
                errors=validation.errors if validation else [],
                confidence_score=confidence_score,
                processing_notes=processing_notes,
                total_cards=len(validated_cards),
                main_count=len(main_tuples),
                side_count=len(side_tuples)
            )

        except Exception as e:
            logger.error(f"‚ùå Erreur critique dans le pipeline: {e}", exc_info=True)
            return ParseResult(
                errors=[f"Erreur critique: {str(e)}"],
                processing_notes=[f"Pipeline interrompu √† cause de: {type(e).__name__}"]
            )

    def extract_text_from_image(self, image_path: str) -> List[str]:
        """M√©thode de compatibilit√© pour l'ancien code"""
        raw_text = self.arena_ocr.extract_text_from_image(image_path)
        return raw_text.split('\n') if raw_text else []

# --- Exemple d'utilisation (pour test) ---
async def main_test():
    """Test du parser am√©lior√©"""
    if not os.path.exists('test_deck.png'):
        print("Fichier 'test_deck.png' non trouv√© pour le test.")
        return

    from scryfall_service import ScryfallService
    
    async with ScryfallService() as scryfall:
        parser = MTGOCRParser(scryfall)
        result = await parser.parse_deck_image('test_deck.png')

        print("\n--- R√âSULTAT FINAL ---")
        if result.export_text:
            print(result.export_text)
        else:
            print("Aucun export g√©n√©r√©.")

        if result.errors:
            print("\nERREURS:")
            for e in result.errors:
                print(f"- {e}")
        
        if result.warnings:
            print("\nAVERTISSEMENTS:")
            for w in result.warnings:
                print(f"- {w}")

        print(f"\nSTATISTIQUES:")
        print(f"- Confiance: {result.confidence_score:.1%}")
        print(f"- Cartes totales: {result.total_cards}")
        print(f"- Main: {result.main_count}, Side: {result.side_count}")

if __name__ == '__main__':
    print("Ce fichier est un module et doit √™tre import√©.")
    # Pour tester: asyncio.run(main_test()) 